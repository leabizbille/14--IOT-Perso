import requests
import os

# Cr√©er un dossier pour stocker les fichiers t√©l√©charg√©s (si n√©cessaire)
folder_path= r"C:\Users\Lau\Documents\Moi\1-Travail (sept 23)\3- IA\1- Formation Greta\3- Projets\14- IOT Perso\1-Documents\pdfs"
os.makedirs(folder_path, exist_ok=True)

def download_pdfs(pdf_urls):

    # Cr√©er le dossier et ses parents si n√©cessaire
    os.makedirs(folder_path, exist_ok=True)

    print(f"Dossier '{folder_path}' est pr√™t √† √™tre utilis√©.")

    # T√©l√©charger chaque fichier PDF
    for url in pdf_urls:
        # D√©terminer le nom du fichier √† partir de l'URL
        pdf_filename = os.path.join(folder_path, url.split("/")[-1])
        
        # Effectuer la demande HTTP pour t√©l√©charger le PDF
        response = requests.get(url)
        
        # Sauvegarder le PDF dans le dossier local
        with open(pdf_filename, 'wb') as file:
            file.write(response.content)
        print(f"üì• PDF t√©l√©charg√© : {pdf_filename}")

if __name__ == "__main__":
    from ScrapingPrixEDF import get_pdf_urls  # Importer la fonction pour r√©cup√©rer les URLs des PDF
    pdf_urls = get_pdf_urls()  # R√©cup√©rer les URLs des PDF depuis scraper.py
    download_pdfs(pdf_urls)  # T√©l√©charger les PDFs


